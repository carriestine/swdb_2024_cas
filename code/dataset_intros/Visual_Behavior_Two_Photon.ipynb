{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1a8ea9",
   "metadata": {},
   "source": [
    "![cropped-SummerWorkshop_Header.png](resources/banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e4bcd",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Allen Brain Observatory Visual Behavior Ophys </h1> \n",
    "<h2 align=\"center\"> SWDB 2024 - Day 1 </h2> \n",
    "<h3 align=\"center\"> Afternoon Session </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee240ac",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "The Allen Brain Observatory Visual Behavior Ophys dataset used in vivo 2-photon calcium imaging (also called optical physiology, or “ophys”) to measure the activity of genetically identified neurons in the visual cortex of mice performing a go/no-go visual change detection task. This dataset can be used to evaluate the influence of experience, expectation, and task engagement on neural coding and dynamics in excitatory and inhibitory cell populations. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c91b0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "***What kind of questions can you answer with this dataset?***\n",
    "\n",
    "In this dataset, populations of excitatory or inhibitory neurons were tracked across multiple days of task performance under varying sensory and behavioral conditions, including active behavior and passive viewing, as well as familiar and novel stimuli. In a subset of recordings, multiple cortical areas and depths were simultaneously recorded. The dataset also contains the full training history of all mice as they learned the task across several learning stages. \n",
    "\n",
    "This makes the dataset appropriate for questions about coding for sensory, behavioral, and task features in specific cell populations, as well as analysis of changes in activity patterns over time.\n",
    "\n",
    "- Do excitatory and inhibitory neuron types represent distinct features of stimulus, behavior, or task variables?\n",
    "- How do coding properties change with novelty and familiarization?\n",
    "- Do interactions across cortical areas or depths fluctuate as animal's engagement and motivation changes?\n",
    "- Are there unique subnetworks or ensembles that represent particular types of information?\n",
    "- Do network interactions reorganize as stimuli become familiar? Do they depend on task engagement?\n",
    "- How does expectation alter neural representations? Are there surprise signals in the visual cortex?\n",
    "- Can you predict behavioral choices from neural activity? Which cell populations are most predictive?\n",
    "- How do animals learn the behavioral task? What strategies do they take?\n",
    "- Does animal learning progression influence activity patterns in well trained mice? \n",
    "\n",
    "These are just some of the questions that might be addressed from this type of data.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef31fef",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "**Databook**\n",
    "\n",
    "The databook is your one-stop-shop for understanding the various dimensions of this dataset, the methods used, and how to access the data that you are interested in. \n",
    "\n",
    "You can find the pages for the Visual Behavior Ophys dataset here: https://allenswdb.github.io/physiology/ophys/visual-behavior/VB-Ophys.html \n",
    "\n",
    "![vbo_databook.png](resources/databook_vb2p.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2349f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Using the Python objects we'll show you below, you can extract information about this dataset such as which genetically defined cell populations were imaged, which session types are available, and how to find the same neurons across multiple sessions. \n",
    "\n",
    "The available data for each session includes: \n",
    "- Calcium fluorescence traces and deconvolved events representing neural activity\n",
    "- Running speed and pupil area as measures of arousal and behavioral state\n",
    "- Stimulus presentation times, including times of image changes and image omissions\n",
    "- Licking responses and reward times associated with task performance\n",
    "- Average projection images of 2-photon movies to visualize spatial organization of recorded neurons\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444252c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "## Accessing the data cache\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3af99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to import these modules to get started\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn makes pretty plots & sets font sizes nicely\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'lines.markeredgewidth': 2})\n",
    "\n",
    "# magic functions for jupyter notebook plotting\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c100c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confirm that you are currently using the newest version of SDK (2.16.2)\n",
    "import allensdk\n",
    "allensdk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85d075",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "The code below shows you how to use the `VisualBehaviorOphysProjectCache` class to load metadata tables & explore the features of the dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abdfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the directory where files will be saved\n",
    "# If using Code Ocean, this should link to the data directory, where the files will already be available\n",
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if ('Darwin' in platstring)or('macOS' in platstring):\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on CodeOcean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a1e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import behavior projet cache class from SDK to be able to load the data\n",
    "from allensdk.brain_observatory.behavior.behavior_project_cache import VisualBehaviorOphysProjectCache\n",
    "\n",
    "cache = VisualBehaviorOphysProjectCache.from_local_cache(cache_dir=data_root, use_static_cache=True)\n",
    "# if we needed to download the data we could have used the following line\n",
    "# cache = VisualBehaviorOphysProjectCache.from_s3_cache(cache_dir=data_root)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87acbaa",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "The cache contains methods that allow you to explore the types of recording sessions that exist in the dataset, and to load the data for individual experiments.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15efd0a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "### Load all cache tables\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e98412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 4 metadata tables associated with the Visual Behavior Ophys dataset\n",
    "behavior_session_table = cache.get_behavior_session_table()  \n",
    "ophys_session_table = cache.get_ophys_session_table()   \n",
    "ophys_experiment_table = cache.get_ophys_experiment_table()    \n",
    "ophys_cells_table = cache.get_ophys_cells_table()                         \n",
    "\n",
    "\n",
    "#print number of items in each table \n",
    "print('Number of behavior sessions = {}'.format(len(behavior_session_table)))\n",
    "print('Number of ophys sessions = {}'.format(len(ophys_session_table)))\n",
    "print('Number of ophys experiments = {}'.format(len(ophys_experiment_table)))\n",
    "print('Number of unique cells = {}'.format(len(ophys_cells_table.cell_specimen_id.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e86a45",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "You can check the DataBook to learn more about the different tables, including what all of the columns mean:\n",
    "\n",
    "\n",
    "https://allenswdb.github.io/physiology/ophys/visual-behavior/VBO-Dataset.html#vbo-metadata-tables\n",
    "\n",
    "\n",
    "![vbo_metadata_tables.png](resources/vbo_metadata_tables.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963275c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "## Plot behavior data for one session\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a83de5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "For now we will grab one behavior session and load the data\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a behavior_session_id\n",
    "behavior_session_id = behavior_session_table[behavior_session_table.session_type=='OPHYS_3_images_A'].index.values[9]\n",
    "print(behavior_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for the behavior_session_id we selected \n",
    "behavior_session = cache.get_behavior_session(behavior_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ecb9b-f220-4a8e-9eb8-81b90893712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_session_table.loc[behavior_session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231e48a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "### Plot running speed and stimulus blocks\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ab6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the running_speed attribute of the behavior session\n",
    "running_speed = behavior_session.running_speed.copy()\n",
    "running_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot running alone\n",
    "fig, ax = plt.subplots(figsize=(10, 3.5))\n",
    "ax.plot(running_speed.timestamps, running_speed.speed)\n",
    "ax.set_ylabel('Running speed (cm/s)')\n",
    "ax.set_xlabel('Time in session (seconds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stimulus_presentations table. What columns does it have?\n",
    "stimulus_presentations = behavior_session.stimulus_presentations.copy()\n",
    "stimulus_presentations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71172bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot running speed with stimulus blocks in different colors\n",
    "\n",
    "# Running speed\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(running_speed.timestamps, running_speed.speed)\n",
    "ax.set_ylabel('Running speed (cm/s)')\n",
    "ax.set_xlabel('Time in session (seconds)')\n",
    "\n",
    "# Iterate through stimulus blocks and show them in color\n",
    "# Set colormap\n",
    "colors = sns.color_palette()\n",
    "# Loop through unique stimulus blocks\n",
    "for i, stimulus_block_name in enumerate(stimulus_presentations.stimulus_block_name.unique()): \n",
    "    # Get stimulus metadata for this stimulus block\n",
    "    stimulus_block_data = stimulus_presentations[stimulus_presentations.stimulus_block_name==stimulus_block_name]\n",
    "    # Plot the duration of the stimulus block in color using matplotlib's axvspan\n",
    "    ax.axvspan(xmin=stimulus_block_data.start_time.values[0], xmax=stimulus_block_data.end_time.values[-1], \n",
    "               color=colors[i], alpha=0.25, label=stimulus_block_name)\n",
    "# Add legend to label stimulus blocks\n",
    "ax.legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498bc7b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Theres a lot going on there, let's zoom in on just a few seconds of data\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679f1bd",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "### Plot running speed and task events around the time of an image change\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981c1cf",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Let's get the time of one image change during the `change_detection_behavior block` of the `stimulus_presentations` table and plot the stimulus, `running_speed` and behavior events (`licks` and `rewards`) in a +/- 10 second window around the change time\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54622c8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "First lets define some functions to plot running, licks, and rewards, and stimuli\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e92522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_running_speed_in_window(running_speed, window_start, window_end, ax): \n",
    "    '''\n",
    "    A function to plot running speed in specific window of time on the provided axis\n",
    "    \n",
    "    running_speed: A table including columns for `running_speed` and `timestamps`\n",
    "    '''\n",
    "    # Plot the running speed, in seconds, on the provided axis\n",
    "    ax.plot(running_speed.timestamps, running_speed.speed)\n",
    "    ax.set_ylabel('Running speed (cm/s)')\n",
    "    ax.set_xlabel('Time in session (seconds)')\n",
    "    # Limit to the selected window\n",
    "    ax.set_xlim(window_start, window_end)\n",
    "\n",
    "    # Return axes so we can add other things to it \n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_licks_in_window(licks, window_start, window_end, ax): \n",
    "    '''\n",
    "    A function to plot licks occuring in specific window of time on the provided axis\n",
    "    \n",
    "    licks: A table with timestamps of each lick in the session\n",
    "    '''\n",
    "    # Get licks in the provided window\n",
    "    window_licks = licks[(licks.timestamps>=window_start) & (licks.timestamps<=window_end)]\n",
    "    # Iterate through them and plot as a line\n",
    "    for idx, lick in window_licks.iterrows():\n",
    "        ax.plot(lick.timestamps, -5, '|', color='gray')\n",
    "\n",
    "    # Return axes so we can add other things to it \n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_rewards_in_window(rewards, window_start, window_end, ax): \n",
    "    '''\n",
    "    A function to plot rewards occuring in specific window of time on the provided axis\n",
    "    \n",
    "    rewards: A table with timestamps of each reward in the session\n",
    "    '''\n",
    "    # Get rewards in the provided window\n",
    "    window_rewards = rewards[(rewards.timestamps>=window_start) & (rewards.timestamps<=window_end)]\n",
    "    # Iterate through them and plot as a line\n",
    "    for idx, reward in window_rewards.iterrows():\n",
    "        ax.plot(reward.timestamps, -10, 'o', color='cyan')\n",
    "\n",
    "    # Return axes so we can add other things to it \n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_stimuli_in_window(stimulus_presentations, window_start, window_end, ax): \n",
    "    '''\n",
    "    A function to plot a colored bar for each unique image_name in a specific window of time\n",
    "    within the provided stimulus_presentations table, on the provided axis. \n",
    "    \n",
    "    stimulus_presentations: Table of all stimulus presentations and associated metadata\n",
    "                            Function will limit to the `change_detection_behavior` block when image presentations occur\n",
    "    '''\n",
    "\n",
    "    # Make sure we are only looking at stimuli during the change detection block (other stimulus blocks do not have unique image names)\n",
    "    stimulus_presentations = stimulus_presentations[(stimulus_presentations.stimulus_block_name=='change_detection_behavior')]\n",
    "\n",
    "    # create colormap for unique image names\n",
    "    colors = sns.color_palette('hls', len(stimulus_presentations.image_name.unique()))\n",
    "    image_colors_dict = {}\n",
    "    for i, image_name in enumerate(np.sort(stimulus_presentations.image_name.unique())): \n",
    "        # omissions are white\n",
    "        if image_name == 'omitted': \n",
    "            image_colors_dict[image_name] = [1, 1, 1]\n",
    "        # images are in color\n",
    "        else: \n",
    "            image_colors_dict[image_name] = colors[i]\n",
    "\n",
    "    # Get all stimuli in the provided window\n",
    "    window_stimuli = stimulus_presentations[(stimulus_presentations.start_time>=window_start) & \n",
    "                                          (stimulus_presentations.end_time<=window_end)]\n",
    "\n",
    "    # Create figure axes if not already provided\n",
    "    if ax is None: \n",
    "        fig, ax = plt.subplots(figsize=(10,3))\n",
    "\n",
    "    # Loop through stimuli and plot them\n",
    "    for idx, stimulus in window_stimuli.iterrows():\n",
    "        image_name = stimulus['image_name']\n",
    "        ax.axvspan(stimulus['start_time'], stimulus['end_time'], color=image_colors_dict[image_name], alpha=0.25)\n",
    "\n",
    "    # Return axes so we can add other things to it   \n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e1dcb",
   "metadata": {},
   "source": [
    "Now let's get the stimulus presentations in a short window around one of the changes and provide the data to our plotting fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e685d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get change detection behavior block from stimulus presentations table\n",
    "stimulus_block_name = 'change_detection_behavior'\n",
    "change_detection_stimuli = stimulus_presentations[(stimulus_presentations.stimulus_block_name==stimulus_block_name)]\n",
    "\n",
    "# Get stimulus presentations corresponding to image changes\n",
    "image_changes = change_detection_stimuli[(change_detection_stimuli.is_change==True)]\n",
    "\n",
    "#  Pick one image change start time\n",
    "image_change_time = image_changes.start_time.values[11]\n",
    "\n",
    "# Get a defined window of time around the image change\n",
    "window_start = image_change_time-10\n",
    "window_end = image_change_time+15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stimulus and behavior together in this window using our functions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3.5))\n",
    "\n",
    "# Plot stimuli using function we created, for the subset of stimuli we selected\n",
    "ax = plot_stimuli_in_window(change_detection_stimuli, window_start, window_end, ax)\n",
    "\n",
    "# Plot running speed in the window we selected\n",
    "ax = plot_running_speed_in_window(behavior_session.running_speed, window_start, window_end, ax)\n",
    "\n",
    "# Plot licks in the window we selected\n",
    "ax = plot_licks_in_window(behavior_session.licks, window_start, window_end, ax)\n",
    "\n",
    "# Plot rewards in the window we selected\n",
    "ax = plot_rewards_in_window(behavior_session.rewards, window_start, window_end, ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef6617",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "There are a lot of interesting features in this snippet of behavior: \n",
    "* The first image change (light blue to pink) is a hit trial, because the mouse licked within the 750ms reward window\n",
    "* The second image change (pink to purple) is a miss, because the mouse did not respond fast enough\n",
    "* There is a false alarm lick a few image repetitions after the second image change\n",
    "* There is a stimulus omission, during which the mouse does not lick or stop\n",
    "* However there is a slight change in running speed after the omission - maybe the mouse thought it was a change?\n",
    "* The third image change (purple to green) was a hit trial\n",
    "* The mouse appears to have slowed down a little prior to the third image change, and as a result, may have had a faster reaction time. Is the mouse trying to anticipate when the changes might occur??\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190a104",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "## Evaluating task performance\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedd9e3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "In the snippet of behavioral data above, we saw some cases where the mouse correctly responded to a change and others when it did not. \n",
    "\n",
    "How can we evaluate the mouse's overall performance? \n",
    "\n",
    "There are a few additional data structures that can help with this. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ea102",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "### How many hit and miss trials are there? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ed1d6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "We can use the `trials` table to quantify the number of hits and misses\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef009b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = behavior_session.trials.copy()\n",
    "trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec498ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the number of hits and misses\n",
    "print('out of', len(trials[trials.go]), 'go trials (i.e. image changes)' )\n",
    "print(len(trials[trials.hit]), 'were hits')\n",
    "print('and', len(trials[trials.miss]), 'were misses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8350c11",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "To learn more about the task's trial structure, how catch trials are defined, and how false alarm rates can be computed, you can check the DataBook: https://allenswdb.github.io/physiology/ophys/visual-behavior/VB-BehaviorSessionData.html \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309428a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "#### Pre-computed metrics of task performance\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e247a73",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "What about other metrics of performance? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5296ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conveniently, there is also a table provided with summary metrics of performance\n",
    "behavior_session.get_performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb65719",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "You can check the DataBook to see how these metrics were defined: https://allenswdb.github.io/physiology/ophys/visual-behavior/VB-BehaviorSessionData.html#evaluate-behavior-performance-across-all-sessions-for-this-mouse\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these metrics are also provided in the `behavior_session_table` so that you can filter sessions based on task performance\n",
    "\n",
    "behavior_session_table.loc[behavior_session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d741b6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Hmm this mouse wasn't doing great... Was it missing changes consistently the whole session? Or do they all occur at a specific time? \n",
    "\n",
    "It looks like there were only 157 engaged trials, out of 304 total go trials. Maybe the mouse disengaged at some point in the session and started missing lots of changes. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a373c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is another table that provides continous measures of behavior performance across the session\n",
    "rolling_performance_df = behavior_session.get_rolling_performance_df()\n",
    "rolling_performance_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the reward rate over trials. This can be used as a metric of task engagement. \n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "\n",
    "ax.plot(rolling_performance_df.index, rolling_performance_df.reward_rate)\n",
    "ax.set_ylabel('Reward rate\\n(rewards / second)')\n",
    "ax.set_xlabel('Trial #')\n",
    "ax.set_ylim(0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce55f88",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "## Plot neural activity for one imaging plane during a session \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd66cf8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Above we looked at a behavior session using the `behavior_session_table`. Sometimes behavior sessions also have ophys, but other times they dont, for sessions where the mouse was still learning the task, or ophys sessions where the QC criteria were not met (but the behavior data is still provided). \n",
    "\n",
    "To get ophys sessions you can use the `ophys_session_table`. If you have read the Visual Behavior Ophys page of the DataBook you will know that each ophys session could contain multiple imaging planes, and the ophys data is provided on a plane by plane basis. \n",
    "\n",
    "To identify individual imaging planes within a given ophys session, you use the `ophys_experiment_table`. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb82252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ophys_experiment_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an experiment - the first one in the table\n",
    "ophys_experiment_id = ophys_experiment_table.index.values[0]\n",
    "print(ophys_experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using the cache\n",
    "ophys_experiment = cache.get_behavior_ophys_experiment(ophys_experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check metadata to see what conditions this experiment was performed under\n",
    "ophys_experiment.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb8940",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "What do the cells look like? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ee3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the maximum intensity projection\n",
    "plt.imshow(ophys_experiment.max_projection, cmap='gray', vmin=0, vmax=np.percentile(ophys_experiment.max_projection, 99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2665f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "#### Get the cell activity traces and plot dF/F and events for one cell\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalized fluorescence traces\n",
    "dff_traces = ophys_experiment.dff_traces.copy()\n",
    "dff_traces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deconvolved events\n",
    "events = ophys_experiment.events.copy()\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ophys timestamps\n",
    "ophys_timestamps = ophys_experiment.ophys_timestamps.copy()\n",
    "ophys_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dF/F and events for one cell\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(ophys_timestamps, dff_traces.iloc[0]['dff'], color='gray', label='dF/F')\n",
    "ax.plot(ophys_timestamps, events.iloc[0]['events'], color=sns.color_palette()[0], label=events)\n",
    "ax.set_xlabel('Time in session (seconds)')\n",
    "ax.set_ylabel('dF/F')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517938d0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "### Plot events for all cells\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot events for all cells\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i, cell_specimen_id in enumerate(events.index.values): \n",
    "    ax.plot(ophys_timestamps, events.loc[cell_specimen_id]['events']+(i*2), color='gray')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96b46d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Why are some cells so active at the end?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5846d3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Get the `stimulus_presentations` table for this experiment and plot the stimulus blocks along with the traces, like we did before for running speed\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67080e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot events for all cells\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i, cell_specimen_id in enumerate(events.index.values): \n",
    "    ax.plot(ophys_timestamps, events.loc[cell_specimen_id]['events']+(i*2), color='gray')    \n",
    "\n",
    "# Iterate through stimulus blocks and show them in color\n",
    "colors = sns.color_palette()\n",
    "for i, stimulus_block_name in enumerate(stimulus_presentations.stimulus_block_name.unique()): \n",
    "    stimulus_block_data = stimulus_presentations[stimulus_presentations.stimulus_block_name==stimulus_block_name]\n",
    "    ax.axvspan(xmin=stimulus_block_data.start_time.values[0], xmax=stimulus_block_data.end_time.values[-1], \n",
    "               color=colors[i], alpha=0.25, label=stimulus_block_name)\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "ax.set_xlabel('Time in session (seconds)')\n",
    "ax.set_ylabel('Event magnitude (a.u.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4bb21c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Looks like there are a whole variety of response patterns. Some cells respond during the change detection behavior block, while others respond most during the natural movie stimulus. Some cells are active during the gray screen period, and others arent. \n",
    "\n",
    "Look at the very last cell at the bottom of the plot - that cell appears to be suppressed by the natural movie stimulus compared to during the task or gray screen periods. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35c1ee",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "#### Let's zoom in on one cell's activity and look at the dynamics\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the first cell (index 0), and limit the plot to a 40 second window during the session\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(ophys_timestamps, dff_traces.iloc[0]['dff'], color='gray', label='dF/F')\n",
    "ax.plot(ophys_timestamps, events.iloc[0]['events'], color=sns.color_palette()[0], label=events)\n",
    "ax.set_xlim(1000, 1040)\n",
    "ax.set_xlabel('Time in session (seconds)')\n",
    "ax.set_ylabel('dF/F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98dc1d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "What is causing this cell to be active in such a regular pattern? Is it the stimulus? What else could be happening that could cause this pattern of cell activation? What could this cell encode?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80cded0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "## What else is available as part of this dataset? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967f315",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "There are many more dimensions to this dataset than we were able to explore here. Combined with the DataBook, the exercises below will help you learn how to discover what else is available for your analysis. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c9541",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "<h4> Explore Further</h4>\n",
    "<p>Use the DataBook as a reference to learn how to access and interpret different features of the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2e887",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "<h3>Exploring metadata tables for sessions and cells of interest </h3>\n",
    "\n",
    "You can learn about the various conditions and session types available in the dataset here: \n",
    "\n",
    "https://allenswdb.github.io/physiology/ophys/visual-behavior/VBO-Dataset.html\n",
    "\n",
    "<p>\n",
    "\n",
    "**Cell types, imaging depths, and targeted structures**\n",
    "1. What are the unique values of `full_genotype` in the behavior or ophys session tables? What is a `cre_line`?\n",
    "2. What are the unique values of `imaging_depth` and `targeted_structure`? Does each ophys session have just one of each, or can there be more than one? \n",
    "3. What are the unique values of `project_code`? Explore the DataBook to figure out what these mean.\n",
    "4. For a session with `project_code` = `VisualBehaviorMultiscope` session, what are the imaging depths and targeted structures that were recorded? What about other project codes?\n",
    "<p>\n",
    "\n",
    "**Tracking the same neurons across sessions**\n",
    "1. What does the `ophys_cells_table` contain? Can you link the information in this table with the `ophys_experiment_table`?\n",
    "2. Find a `cell_specimen_id` in the `ophys_cells_table`. How many unique `ophys_experiment_id`s is it associated with? \n",
    "3. What are the unique values of `session_type` in the metadata tables? Are they different in the `behavior_session_table` and `ophys_session_table`?\n",
    "4. What is the `prior_exposures_to_image_set` column of the metadata tables? What is the `experience_level` column? How about the `image_set` column? How do they relate to each other?\n",
    "5. What are the unique values of the `passive` column of the metadata tables? What `session_types` exist for passive vs. active? \n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966212f4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>\n",
    "    \n",
    "### Exploring neural activity and relationships to stimulus and behavior\n",
    "\n",
    "You can learn about how to load, visualize, and analyze data for individual behavior sessions or ophys experiments here: \n",
    "\n",
    "https://allenswdb.github.io/physiology/ophys/visual-behavior/VBO-ExperimentData.html \n",
    "\n",
    "https://allenswdb.github.io/physiology/ophys/visual-behavior/VB-BehaviorSessionData.html\n",
    "\n",
    "\n",
    "**Neural activity & transgenic lines**\n",
    "1. What do the max intensity projections look like for different genotypes? \n",
    "2. How many cells are there in experiments from different genotypes? \n",
    "3. What do single cell and population activity look like for different genotypes?\n",
    "<p>\n",
    "\n",
    "**Stimulus & behavior**\n",
    "1. What are all the unique columns of the `stimulus_presentations` table? \n",
    "2. Investigate relationship of running speed and pupil diameter for image changes and image omissions\n",
    "<p>\n",
    "\n",
    "**Changes in activity with novelty and behavioral context**\n",
    "1. Plot neural activity across stimulus blocks or trial types for familiar vs novel for the same cells\n",
    "2. Plot running & pupil across stimulus blocks or trial types for active & passive sessions for the same mouse\n",
    "<p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36856239",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "A little preview of what you can find in the DataBook... \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32945a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "## Longitudinal imaging across sensory and behavioral contexts\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24d2db",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "A key feature of the Visual Behavior Ophys dataset is that populations of neurons were tracked across multiple days of imaging under varying sensory and behavioral conditions. \n",
    "\n",
    "So far we only looked at activity for one type of session, but there are many types of sessions and many exciting analyses can be done to understand how neural coding and dynamics change over time, such as with novelty and familiarization, or with behavioral state. \n",
    "\n",
    "These different session types, and how to access the data for them, is described in the databook: \n",
    "\n",
    "https://allenswdb.github.io/physiology/ophys/visual-behavior/VB-Ophys.html#experimental-design \n",
    "\n",
    "\n",
    "![vbo_expt_design.png](resources/vbo_expt_design.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64486697",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "In addition, a subset of the dataset includes simultaneous recordings across multiple cortical areas and depths, allowing analysis of interactions and information flow. \n",
    "\n",
    "Yet again, you can find more information about the structure of the data in the DataBook! \n",
    "\n",
    "https://allenswdb.github.io/physiology/ophys/visual-behavior/VB-Ophys.html#data-structure\n",
    "\n",
    "\n",
    "![data_structure.png](resources/data_structure.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ada13d-a0ad-4f48-982a-a74c534b8459",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 1***\n",
    "\n",
    "Plot the pupil diameter during a session.  Plot the image change times on the same axes.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15556750-049e-4914-afc3-913f67a90946",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 2***\n",
    "\n",
    "Find a cell that was recorded across multiple sessions and plot its response to image changes and image omissions. Does its activity change across days? What was different about the sessions that could explain these changes?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcae81-b691-4e1d-9181-34f5ac4d9cfe",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 3***\n",
    "\n",
    "Compute the lick rate during change trials and during omissions.  Do mice lick after omissions?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.770791,
   "end_time": "2023-07-31T19:18:26.861555",
   "environment_variables": {},
   "exception": null,
   "input_path": "doc_template/examples_root/examples/nb/visual_behavior_load_ophys_data.ipynb",
   "output_path": "/tmp/tmpcq7t4kmr/scratch_nb.ipynb",
   "parameters": {
    "output_dir": "/tmp/tmpcq7t4kmr",
    "resources_dir": "/home/runner/work/AllenSDK/AllenSDK/allensdk/internal/notebooks/resources"
   },
   "start_time": "2023-07-31T19:17:20.090764",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
