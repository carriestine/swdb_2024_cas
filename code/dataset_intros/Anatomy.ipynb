{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51f6dc4-0a18-4796-8180-c20287187e53",
   "metadata": {},
   "source": [
    "![Image](resources/banner.jpg)\n",
    "\n",
    "<h1 align=\"center\">Workshop SWDB 2024 </h1> \n",
    "<h3 align=\"center\">Day 1 2024 - Anatomy Introduction</h3> \n",
    "<h3 align=\"center\">Notebook 0: Load and View neuron skeletons</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377b808-2647-4d3f-a06d-86ae59620f3b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "<p>Analyzing neuron morphology data begins with accessing it--and understanding how the data is structured. This notebook provides an example of how to load, examine, and visualize a neuron skeleton in both 2D and 3D. We introduce these tools by exploring two different datasets containing neurons that were imaged with <b>Electron Microscopy (EM) </b>and <b>Lightsheet Microscopy (LM).</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84b2dc-27cc-4c87-99ef-7574554db55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "import os\n",
    "\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe779454-f761-4059-8d9e-fb7f4f4e338b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "This cell sets up a variable called `data_root` that you should use in any code below to access the dataset in question (e.g. paths to manifest files for the SDK should be made relative to this variable).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2928a-a2b4-4806-9da0-6c600c8ad9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if ('Darwin' in platstring) or ('macOS' in platstring):\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/anatomy\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/anatomy\"\n",
    "elif ('amzn2' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/anatomy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e4645-9f78-4f19-bdda-d575adb84f2b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    " \n",
    "<h2> Load the Skeleton Data from the precomputed format </h2>\n",
    "    \n",
    "<p> Neuroglancer is a web-based application for visualizing large-scale biological images and neuron morphology datasets. This tool requires that the data is stored as a \"Precomputed\" file, which is a format designed for large volumetric images, meshes, and skeletons. Our neuron data is stored in this precomputed skeleton format and we will use a python library called CloudVolume to load the neurons from both the Electron Microscopy (EM) and Lightsheet Microscopy (LM) datasets.\n",
    "    \n",
    "<p> <b> Any of the skeletons you selected in the neuroglancer demo, you can download and visualize here </b>\n",
    "    \n",
    "<p> <font size=4> <a href=https://spelunker.cave-explorer.org/#!middleauth+https://global.daf-apis.com/nglstate/api/v1/6703999991414784>Neuroglancer Demo in CCF </a> </font> </b>\n",
    "    \n",
    "<p> Below we import the package <a href=\"https://github.com/seung-lab/cloud-volume\">CloudVolume</a>, which is a serverless Python client for random access reading and writing of Neuroglancer volumes in <a href=\"https://github.com/google/neuroglancer/blob/master/src/datasource/precomputed/skeletons.md\">\"Precomputed\"</a> format, a set of representations for arbitrarily large volumetric images, meshes, and skeletons. \n",
    "\n",
    "<p> We will use cloudvolume to load precomputed skeletons from first the Electron Microscopy (EM) data and second Lightsheet Microscopy (LM) data.\n",
    "    \n",
    "<p> Note: For this course we have pre-loaded the data into the capsule or the hard drive. However, the data is the same you see in neuroglancer and can be accessed with the same cloud path. For example: <code>input_directory = \"precomputed://gs://allen_neuroglancer_ccf/em_minnie65_v1078\"</code>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fd2f2-d607-4f62-94d2-77660d5897cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cloudvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908e604-be56-421d-a0b6-33c3eab0775f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#EM Data\n",
    "input_directory = f\"file://{data_root}/ccf_em_minnie65_v1078\"\n",
    "skeleton_id = 864691135591041291\n",
    "cv_obj = cloudvolume.CloudVolume(input_directory) # Initialize cloud volume\n",
    "cv_sk = cv_obj.skeleton.get(skeleton_id) #load an example skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297533d2-27d1-4d56-adc0-31c83c5a5929",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p> A precomputed skeleton is a simplified representation of a neuron where its shape is captured by a tree-like structure that passes through the center of the neuron. More specificy, a precomputed skeleton stores a neuron as a graph with vertices and edges in addition to a collection of vertex-attached attributes that capture morphological and anatomical information about the neuron.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c0e38-c242-4168-af54-d7e3a5daee95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"This is a precomputed skeleton of an EM neuron...\\n\")\n",
    "print(cv_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d3d20-49f2-450d-95a1-04f520dda5db",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "\n",
    "<p> Each vertex of the skeleton is an [x,y,z] coordinate. The vertices and their edges form a 'geometric graph' that we will operate on in later notebooks\n",
    "    \n",
    "<p> Note: Observe that many attributes such as \"radius\" and \"compartment\" have the same shape as \"vertices\". Each vertex may also be associated with one or more other properties, including:\n",
    "<ul>\n",
    "    <li> <code>radius</code>: the estimated cross-section radius of the segment\n",
    "    <li> <code>compartment</code>: whether the segment belongs to the axon, dendrite, or soma. \n",
    "</ul>\n",
    "\n",
    "<p>We will see these properties rendered later in this notebook, and discuss the other properties synapse properties in later notebooks. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508aa706-6af8-4288-9d3f-ccddffbf340e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> Convert precomputed skeleton to a meshwork skeleton </h2>\n",
    "    \n",
    "<p><a href=\"https://github.com/CAVEconnectome/MeshParty/\">MeshPary</a> is a package that simplifies the analysis of morphological properties of neurons. A <code>meshwork</code> object can include the 3D meshes of a reconstructed neuron, the skeleton structure of that neuron, and related annotations such as synapse properties and myelination.\n",
    "\n",
    "<p>We will use MeshParty's <code>skeleton</code> object to help plot and analyze the precomputed skeletons.\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54d6e0-886a-4012-9f26-e456dcfe334f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from meshparty import skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8116a-1e2b-49fa-b367-30db3755f0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sk = skeleton.Skeleton(cv_sk.vertices, \n",
    "                       cv_sk.edges, \n",
    "                       vertex_properties={'radius': cv_sk.radius,\n",
    "                                          'compartment': cv_sk.compartment},  \n",
    "                       root = len(cv_sk.edges), \n",
    "                       remove_zero_length_edges = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56160b5-264b-4af5-80f7-dda7e9b7e278",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h2> Plot Skeleton in 2D </h2>\n",
    "    \n",
    "<p> <a href=\"https://github.com/AllenInstitute/skeleton_plot\">Skeleton-plot</a> provides some handy utilities for plotting meshwork skeletons, including:\n",
    "<ul>\n",
    "<li> specifying the 2D orientation\n",
    "<li> annotating somas\n",
    "<li> labeling compartments by color\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399043f5-b98d-4458-ac37-e94c7978e6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import skeleton_plot as skelplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b2846-e45d-4f70-84bb-ea6708ddeb2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 10))\n",
    "skelplot.plot_tools.plot_skel(\n",
    "    sk,\n",
    "    line_width = 1,\n",
    "    plot_soma = True,\n",
    "    invert_y = True,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    ")\n",
    "\n",
    "ax.spines['right'].set_visible(False) \n",
    "ax.spines['left'].set_visible(False) \n",
    "ax.spines['top'].set_visible(False) \n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800522af-9419-4a1b-9111-e12684fa92f5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p> Here we have the example neuron rendered in 2D. You can change the plot properties such as: line width, axis orientation, and axes appearance. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6b8cf-7995-4af2-93a9-b6314972bf2d",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1.1:</b>  Try changing the projection from x-y to y-z to see how that changes your perception of the 3D structure\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08a090-6958-4e08-90a4-2dd8c754a772",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h2> Add radius and compartment labels </h2>\n",
    "    \n",
    "<p> To get a more accurate understanding of the neuron's morphology, you can pull in information about the radius and compartment labels into your visualization. \n",
    "    \n",
    "<p>Here the axon is colored black, basal dendrites 'firebrick' red, apical dendrites 'salmon' orange, and the soma a green 'olive'.\n",
    "    \n",
    "<p> <b>Compartment label conventions</b> (from standardized swc files <a href=\"www.neuromorpho.org\">www.neuromorpho.org</a> )\n",
    "<ul>\n",
    "<li> 0 - undefined\n",
    "<li> 1 - soma\n",
    "<li> 2 - axon\n",
    "<li> 3 - (basal) dendrite\n",
    "<li> 4 - apical dendrite\n",
    "<li> 5+ - custom\n",
    "</ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bea1b0-a99d-4625-8209-5107b13e73cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 10))\n",
    "skelplot.plot_tools.plot_skel(\n",
    "    sk,\n",
    "    title=\"Neuron with radius and compartments\",\n",
    "    line_width=1,\n",
    "    plot_soma=True,\n",
    "    soma_size = 150,\n",
    "    pull_radius=True,\n",
    "    invert_y=True,\n",
    "    pull_compartment_colors=True,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    skel_color_map = { 1: \"olive\", 2: \"black\", 3: \"firebrick\",4: \"salmon\", },\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.spines['right'].set_visible(False) \n",
    "ax.spines['left'].set_visible(False) \n",
    "ax.spines['top'].set_visible(False) \n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77523cda-2a60-40c2-9e03-8049ced59c83",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1.2:</b>  Change the <code>skel_color_map</code> colors to suit your visual preference. \n",
    "\n",
    "<p> To see more plotting features, enter <code>skelplot.plot_tools.plot_skel?</code> to see the function documentation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf18013-c1e6-454b-b894-e879a69186a1",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h3> Plot skeleton in 3D (with k3d) </h3>\n",
    "\n",
    "<p> Of course, neurons are three-dimensional structures, and so we also want to inspect their morphology in 3D. For this, we will use the interactive 3D rendering package, k3d.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931aeb1-b0ee-49f9-aed2-3a29fe2585b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define plotting functions to turn a skeleton into line objects\n",
    "def plot_graphs(graphs, plot, color = None):\n",
    "    \n",
    "    for i, g in enumerate(graphs):\n",
    "        if color == None:\n",
    "            colorstr = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "            c  = int(colorstr, 16) + 0x200\n",
    "        elif type(color) == type([]):\n",
    "            c = color[i]\n",
    "        else:\n",
    "            c = color\n",
    "        g_lines = graph_to_lines(g,c)\n",
    "        plot += g_lines\n",
    "        \n",
    "\n",
    "def graph_to_lines(g,color=None):\n",
    "    # Extract vertex positions\n",
    "    g_verts = g.vertices\n",
    "    \n",
    "    # Pairs of indices into the vertex array are edges\n",
    "    g_inds = g.edges\n",
    "    \n",
    "    # Could add iteration here to plot compartments in different colors\n",
    "    \n",
    "    g_lines = k3d.factory.lines(g_verts, g_inds, indices_type='segment', width=1, shader='simple',color=color)\n",
    "    return g_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bba776-e80e-429c-995d-bc64cacd314c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "plot_graphs([sk], plot)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae9a9a-7b04-41ca-9e98-a8cac0a27668",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<h2> Exercises </h2>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbadfc7d-7cc8-459a-9433-7a05961b5999",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><h3>Load an Light Microscopy (LM) cell</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7d944-640e-4f99-90f1-98bedd5a1d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Example Cell to Load:\n",
    "input_directory = f\"file://{data_root}/exaSPIM_609281_2022-11-03_13-49-18_reconstructions/precomputed/\"\n",
    "\n",
    "skeleton_id = 1\n",
    "cv_obj = cloudvolume.CloudVolume(input_directory) # Initialize cloud volume\n",
    "cv_sk = cv_obj.skeleton.get(skeleton_id) #load an example skeleton\n",
    "\n",
    "\n",
    "sk = skeleton.Skeleton(cv_sk.vertices, \n",
    "                       cv_sk.edges, \n",
    "                       vertex_properties={'radius': cv_sk.radius,\n",
    "                                              'compartment': cv_sk.compartment,\n",
    "                                              'allenId': cv_sk.allenId},\n",
    "                       root = 0, \n",
    "                       remove_zero_length_edges = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597162b8-4c6e-4a9e-89fc-e63bff0ae862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6b567-1a39-47d7-8007-235b01947864",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Exercise 1.1:</b>  Look at the vertex_properties of the skeleton object. How many unique compartment types are there? What vertex-level attributes does the EM neuron have that the LM neuron lacks? What attribute does the LM neuron have that the EM neuron does not? Why are these different in these ways?\n",
    "    \n",
    "(Note that the LM neurons do not have radii associated with vertices and are set to 1)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e057a4-127f-440d-9bdb-86feadd540b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26d8a7dd-0d5b-4650-b828-ff87b57117a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Exercise 1.2:</b>  View it in 2D\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061dfdd-c131-471e-9160-756741760549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a21bb74-0a43-4b03-a915-02faf837214c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Exercise 1.3:</b>  View it in 3D\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb05744-483d-482b-83c4-71edce3e735d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f605313b-3588-48a4-a086-a2a7883414db",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Exercise 1.4:</b>  View it with colored compartments\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e703005-a670-4110-9eab-093f3834d024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "948e0598-75eb-48ae-a117-e6590cf50802",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Exercise 1.5:</b>  Visualize an LM neuron within a CCF mesh of the whole brain.. We've provided some code to get you started below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b3997-83e3-4ca4-abde-791ad48207e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "def get_whole_ccf_mesh():\n",
    "    mesh_path = os.path.join(data_root, \"AllenCCFMesh\", \"MouseBrainAllen3.obj\")\n",
    "    with open(mesh_path) as f:\n",
    "        return trimesh.load(f, 'obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6f8a6-913a-4c82-87ae-e88455f40943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n",
    "\n",
    "# Add whole brain CCF mesh\n",
    "ccf_mesh = get_whole_ccf_mesh()\n",
    "mesh_plot = k3d.mesh(ccf_mesh.vertices*1000, ccf_mesh.faces, opacity=0.2, color=808080)\n",
    "plot += mesh_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fe45b-2c87-4b14-a971-68d2c8bbc9d5",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Exercise 1.6:</b>  What CCF structure is the soma located in?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84edcfc7-49f5-4cdd-990d-46dbc1909fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7d87f-1174-4aa2-90c0-63db6877efb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
