{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cea343b",
   "metadata": {},
   "source": [
    "![Image](resources/banner.jpg)\n",
    "\n",
    "<h1 align=\"center\">Allen Brain Observatory Visual Coding Neuropixels </h1> \n",
    "<h2 align=\"center\"> Day 1, Morning Session. SWDB 2024 </h2> \n",
    "\n",
    "<h3 align=\"center\">Monday, August 19, 2023</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ef846",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "The Allen Brain Observatory Visual Coding Neuropixels dataset is a large-scale survey of physiological activity in mouse visual cortex in response to a variety of visual stimuli under passive viewing conditions.  The animals are head-fixed but free to run on a disc.  Electrophysiological recording with Neuropixels probes is performed in different areas and layers.  This notebook is a brief introduction to get you started with this data set and lead you to resources for you to explore further.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a5bc18",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "***What kind of questions can you answer with this dataset?***\n",
    "\n",
    "This dataset contains recordings of activity in response to a variety of natural and artificial visual stimuli.  This makes it suitable for a variety of coding questions.\n",
    "\n",
    "- How are stimuli and features from the external world encoded in neural responses?  \n",
    "- How do the encoding properties differ across areas and layers?  In different cell lines?\n",
    "- Can you build predictive models of response from stimuli?\n",
    "- How are running activity and pupil size related to cortical activity?\n",
    "- How can information about the stimuli and/or the animal's state be extracted from neural activity?  Can you decode stimuli?\n",
    "- Do neurons coordinate their activity?  Do the act in ensembles?  \n",
    "- Is there any spatial aspect to neural information?\n",
    "\n",
    "These are just some of the questions that might be addressed from this type of data.  \n",
    "\n",
    "***Why electrophysiology?***\n",
    "\n",
    "- You get high temporal resolution.\n",
    "- You are able to see low firing rate activity (but not a complete lack of activity).\n",
    "\n",
    "***Why NOT electrophysiology?***\n",
    "\n",
    "- A more constrained spatial arrangement of recordings.\n",
    "- No firing whatsoever means you never record the cell.\n",
    "- Limited number of units per areas relative to two-photon imaging.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d4a4d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "**Databook**\n",
    "\n",
    "The databook is a resource for more in-depth information and examples for the Allen Brain Observatory Visual Coding Two-photon dataset.  You can find the pages for this data set here:  https://allenswdb.github.io/physiology/ephys/visual-coding/vcnp.html\n",
    "\n",
    "![Image](resources/databook_vcnp.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73cc60",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "***Remember the tools you have!***\n",
    "\n",
    "- Use the databook as a reference; this notebook contains only a small portion of what is in the databook!\n",
    "- Use the help function to find function arguments\n",
    "- Use `dir` to see data and functions in an object\n",
    "- Use tab complete in jupyter \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1d816",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Using the Python objects we'll show you below, you can extract information about this dataset such as how many recordings are available.\n",
    "\n",
    "For each ...\n",
    "\n",
    "- Spike times for identified units\n",
    "- quality control metrics\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b20fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import platform, os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe746add",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "The following cell sets up a path variable so that this notebook will work on the cloud or using data accessed locally, e.g. from your hard drive.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab0349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set file location based on platform. \n",
    "platstring = platform.platform()\n",
    "if ('Darwin' in platstring) or ('macOS' in platstring):\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on Code Ocean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a5697",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "This dataset is accessed via the `allensdk` python package.  It requires instantiating an `EcephysProjectCache` object that we usually call `cache`.  You'll access all of the data for this dataset using this object.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe262c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716fe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manifest_path = os.path.join(data_root, \"allen-brain-observatory/visual-coding-neuropixels/ecephys-cache/manifest.json\")\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7566b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache.get_all_session_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3537c",
   "metadata": {},
   "source": [
    "![Image](resources/neuropixels_stimulus_sets.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fc337",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "You can get information about which sessions are available with the following:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d3bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sessions = cache.get_session_table()\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f793309",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Data on an individual session can be accessed by using the method `get_session_data` with the `cache` object.  It takes an argument that is the session id.  This is the index of the table returned as `sessions` above.\n",
    "\n",
    "If your data is not mounted correctly, you should get a download warning here.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9603b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_id = 715093703\n",
    "session_data = cache.get_session_data(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142916b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Two important sources of information about each session are the `metadata` and the `structurewise_unit_counts`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b995b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f058da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_data.structurewise_unit_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5e273-ed95-4c04-bd57-fc1e9dde2651",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Information on each unit is contained in the units table accessed with `session_data.units`. This is indexed on the unique id for each unit.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f587ae-ba46-42b0-8ed0-5e74414d1b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_data.units.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990fd627-3118-4dfd-9421-418d6d522ecd",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Let's get the id for the first unit\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3a868-4cc7-4e29-b373-75cbd9540d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unit_id = session_data.units.index[0]\n",
    "print(unit_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff067997",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Recorded spike times can be accessed with `session_data.spike_times`, which returns a dictionary whose keys are unit ids and values are numpy arrays of individual spike times in seconds. Let's look at the unit we identified above\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff4682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_data.spike_times[unit_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6e8f9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Let's make a raster plot of spike times for all the units in VISp.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec229ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_units = session_data.units\n",
    "visp_units = session_units[session_units.ecephys_structure_acronym=='VISp']\n",
    "visp_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b2844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visp_spike_times = {uid: st for uid, st in session_data.spike_times.items() if uid in visp_units.index}\n",
    "len(visp_spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de101a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "for i, (unit_id, st) in enumerate(visp_spike_times.items()):\n",
    "    ax.plot(st, np.zeros(len(st))+i, 'ko', markersize=1)\n",
    "    \n",
    "ax.set_ylabel('VISp unit index')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_title('Spike raster for VISp units recorded in session {}'.format(session_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f73664",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "Why are there gaps in the spike times?  Occasionally there were issues with a recording session that did not invalidate the whole experiment, but did invalidate time intervals within the experiment.  You can see these times directly with `session_data.get_invalid_times`.  For some analyses you may have to be aware of these times and explicitly account for them.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ef785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_data.get_invalid_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540b448-8559-49ba-9c78-8930b5d30b97",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "There isn't much detail in that raster plot above, so let's zoom in:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011840c-3e96-46b0-9978-00a00fb16c5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "t_start = 1000\n",
    "t_end = 1010\n",
    "\n",
    "for i, (unit_id, st) in enumerate(visp_spike_times.items()):\n",
    "    st_temp = st[np.where(np.logical_and(st>=t_start, st<t_end))]\n",
    "    ax.plot(st_temp, np.zeros(len(st_temp))+i, 'ko', markersize=1)\n",
    "    \n",
    "ax.set_ylabel('VISp unit index')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_title('Spike raster for VISp units recorded in session {}'.format(session_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b3605",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "We can retrieve the time intervals during which certain stimulus types were shown via `get_stimulus_epochs`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa721e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stimulus_epoch_table = session_data.get_stimulus_epochs()\n",
    "stimulus_epoch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd25ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "for i, (unit_id, st) in enumerate(visp_spike_times.items()):\n",
    "    ax.plot(st, np.zeros(len(st))+i, 'ko', markersize=1)\n",
    "    \n",
    "ax.set_ylabel('VISp unit index')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_title('Spike raster for VISp units recorded in session {}'.format(session_id))\n",
    "\n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c, stim_name in enumerate(session_data.stimulus_names):\n",
    "    stim = stimulus_epoch_table[stimulus_epoch_table.stimulus_name==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(xmin=stim[\"start_time\"].iloc[j], xmax=stim[\"stop_time\"].iloc[j], color=colors[c], alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708684b7",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "***Explore Further***\n",
    "\n",
    "- In addition to the session_table, we looked at above, the cache object also has tables for the probes, the channels, and the individual units.  Call the function that returns these tables.  What information do they contain?\n",
    "\n",
    "- The running speed and pupil size are also available in these data.  Find out how to return them and add them to the plot above.\n",
    "\n",
    "- Units have quality control metrics and there are default values that we consider \"good\" units.  What are these default values and what is the distribution of these metrics?  Plot these distributions.\n",
    "\n",
    "- These data also have LFP available.  How you access this?  Plot the LFP for a single probe in a session.\n",
    "\n",
    ":::{admonition} Hint\n",
    ":class: dropdown\n",
    "Remember to check the [Databook](https://allenswdb.github.io/physiology/ephys/visual-coding/vcnp.html)!\n",
    ":::\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc90f5",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 1***\n",
    "\n",
    "How many sessions are there with Pvalb mice with the `brain_observatory_1.1’ stimulus?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77caec-cd7d-4dc0-a8b1-b7a437a5a88a",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 2***\n",
    "\n",
    "Select a recording session.  Make a plot of the distribution of mean firing rates per brain structure.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbc91d-ef83-431d-a517-4a170b7c7651",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 3***\n",
    "\n",
    "Select a recording session, then select a unit within that session.  To which image does that unit have it’s largest mean response? Make a raster plot of this unit’s response to that image.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df3776c",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "***Homework 4***\n",
    "\n",
    "We plotted the stimulus epochs above.  Pick an individual stimulus (e.g. a particular natural scene) and remake the plot above by shading when that particular stimulus was shown.  For natural stimuli, make a figure with the exact stimulus shown.\n",
    "\n",
    ":::{admonition} Hint #1\n",
    ":class: dropdown\n",
    "You will need the `stimulus_table`.  Look inside the `session_data` object or check the data book to see how to find this.\n",
    ":::\n",
    ":::{admonition} Hint #2\n",
    ":class: dropdown\n",
    "For natural stimuli, you'll want the `stimulus_template`.  Look inside the `cache` object or check the data book.\n",
    ":::\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
